OPENAI_API_KEY=sk-...
DATABASE_URL=postgresql://rag:rag@localhost:5432/ragchat
CORS_ORIGIN=http://localhost:5173

# Qdrant Configuration
QDRANT_URL=http://localhost:6333
QDRANT_COLLECTION=chunks

# AI Models
EMBEDDING_MODEL=text-embedding-3-small
EMBEDDING_DIMENSIONS=1536
CHAT_MODEL=gpt-4o-mini
RERANKER_MODEL=BAAI/bge-reranker-base

# Retrieval Configuration
HYBRID_VECTOR_WEIGHT=0.7
HYBRID_KEYWORD_WEIGHT=0.3
RAG_TOP_K=5
USE_DUAL_VECTOR_STORE=true

# Document Processing
CHUNK_SIZE=1000
CHUNK_OVERLAP=100

# Agent Configuration
MAX_AGENT_STEPS=3
MAX_VERIFICATION_LOOPS=2

# Testing
MOCK_OPENAI=0

# SQL Agent (Sprint 1 scaffolding)
ENABLE_SQL_AGENT=false
SQL_AGENT_MAX_ROWS=50
SQL_AGENT_TIMEOUT_MS=400
# Comma-separated list of allowlisted tables/views for read-only SQL agent
SQL_AGENT_ALLOWLIST=documents,chunks,query_rewrites
SQL_AGENT_MAX_JOIN_DEPTH=2
SQL_AGENT_ALLOWED_FUNCS=count,sum,avg,min,max

# Web Search
ENABLE_WEB_SEARCH=false
# Optional approximate location hints for web search
WEB_SEARCH_CITY=
WEB_SEARCH_REGION=
WEB_SEARCH_COUNTRY=
WEB_SEARCH_TIMEZONE=
# low | medium | high
WEB_SEARCH_CONTEXT_SIZE=medium
# Optional: Comma-separated list of allowed domains (max 20)
# Example: WEB_SEARCH_ALLOWED_DOMAINS=wikipedia.org,github.com,stackoverflow.com
WEB_SEARCH_ALLOWED_DOMAINS=wikipedia.org,github.com,stackoverflow.com

# Classifier Configuration
# Use LLM for intelligent query routing (fallback to heuristics if disabled or on error)
USE_LLM_CLASSIFIER=false

# Grading and Verification Configuration
# Use semantic grading with embeddings for better relevance detection
# When true: uses hybrid 70% semantic + 30% keyword grading
# When false: uses keyword-only grading (faster, less accurate)
USE_SEMANTIC_GRADING=true

# Grade thresholds for chunk relevance scoring (0.0 - 1.0)
# High threshold: chunks with score > this are graded "high"
GRADE_HIGH_THRESHOLD=0.5
# Medium threshold: chunks with score > this are graded "medium"
GRADE_MEDIUM_THRESHOLD=0.2

# Verification threshold for answer validation (0.0 - 1.0)
# Answer must have this % of tokens present in evidence to be verified
VERIFICATION_THRESHOLD=0.5

# Minimum length for tokens to be considered in verification
# Technical terms (AI, ML, API, etc.) are whitelisted regardless of length
MIN_TECHNICAL_TERM_LENGTH=2

# Fallback Configuration
# Enable query rewriting when verification fails (experimental)
ENABLE_QUERY_REWRITING=false

# Allow using low-grade chunks when no high/medium chunks are found
# When true: shows low-confidence results with disclaimer
# When false: returns "no evidence" message
ALLOW_LOW_GRADE_FALLBACK=true

# Cache failure responses (when no evidence is found)
# Set to false to always retry failed queries (useful when corpus is growing)
CACHE_FAILURES=false

# Observability (OpenTelemetry)
# Enable NodeSDK auto-instrumentation and export traces via OTLP HTTP
# Start a local collector (e.g., OpenTelemetry Collector/Tempo) that listens on 4318
ENABLE_OTEL=false
OTEL_SERVICE_NAME=rag-chat-backend
OTEL_EXPORTER_OTLP_ENDPOINT=http://localhost:4318/v1/traces
